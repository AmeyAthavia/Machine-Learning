{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST data for basic operstions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32).reshape(-1,28*28)/255.0      #Change colour to intensity\n",
    "X_test = X_test.astype(np.float32).reshape(-1,28*28)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crearing various Layers of Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp = 28*28         # number of neurons must be same as number of columns of data\n",
    "n_hid1 = 100          #neurons\n",
    "n_hid2 = 50\n",
    "n_out = 10            # as we have 9 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype = tf.float32, shape=(None,n_inp),name = 'x')     # first layer(input layer)\n",
    "Y = tf.placeholder(dtype = tf.int32,shape =(None),name = 'y')             # target  (use to calculate output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating other layers\n",
    "hid1 = tf.layers.dense(inputs = X,units = n_hid1,activation = tf.nn.relu,name = 'hidden1')\n",
    "# dense means fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid2 = tf.layers.dense(inputs = hid1,units = n_hid2,activation = tf.nn.relu,name = 'hidden2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_logist = tf.layers.dense(inputs = hid2,units = n_out,activation = None,name = 'output')\n",
    "#activation is none as want to find xentropy which is only summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding xentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = output_logist,labels=Y)\n",
    "#apply xentropy with logits -> pass it through softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(xentropy)     #cost function  ->mean of xentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the weights using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "gd_optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization = gd_optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some metrices\n",
    "correct = tf.nn.in_top_k(output_logist,Y,1)    #compare Y with top value of logists\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))        #accuracy works with float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.082783334\n",
      "0.111433335\n",
      "0.15283333\n",
      "0.19831666\n",
      "0.25\n",
      "0.30561668\n",
      "0.35845\n",
      "0.40896666\n",
      "0.45621666\n",
      "0.50016665\n",
      "0.5384833\n",
      "0.56695\n",
      "0.59305\n",
      "0.6138667\n",
      "0.63133335\n",
      "0.64676666\n",
      "0.6594167\n",
      "0.67233336\n",
      "0.68331665\n",
      "0.69485\n",
      "0.70463336\n",
      "0.7144333\n",
      "0.7242\n",
      "0.73293334\n",
      "0.7410333\n",
      "0.74916667\n",
      "0.75666666\n",
      "0.7633167\n",
      "0.76998335\n",
      "0.7765667\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epochs in range(n_epochs):\n",
    "        sess.run(optimization, feed_dict = {X:X_train,Y:y_train})    #Running optimiation\n",
    "        print(accuracy.eval(feed_dict = {X:X_train,Y:y_train}))      #Running Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check out keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
